#' ramclustR
#'
#' Main clustering function 
#'
#' This is the Details section
#'
#' @param filename character Filename of the nmrML to check
#' @param ms MS1 intensities =MSdata, 
#' @param idmsms =ms,  
#' @param idMSMStag character e.g. "02.cdf"
#' @param featdelim character e.g. ="_"
#' @param timepos numeric 2
#' @param st numeric no clue e.g. = 5, 
#' @param sr numeric also no clue yet = 5, 
#' @param maxt numeric again no clue =20, 
#' @param deepSplit boolean e.g. =FALSE, 
#' @param blocksize integer number of features (scans?) processed in one block  =1000,
#' @param mult numeric =10
#'
#' @return A vector with the numeric values of the processed data
#' @author Corey Broeckling
#' @export

ramclustR <- function(  xcmsObj=NULL,
                       ms=NULL, 
                       idmsms=NULL,
                       taglocation="filepaths",
                       MStag=NULL,
                       idMSMStag=NULL, 
                       featdelim="_", 
                       timepos=2, 
                       st=NULL, 
                       sr=NULL, 
                       maxt=NULL, 
                       deepSplit=FALSE, 
                       blocksize=2000,
                       mult=5,
                       hmax=NULL,
                       sampNameCol=NULL,
                       collapse=TRUE,
                       usePheno=TRUE,
                       mspout=TRUE, 
                       mslev=1,
                       ExpDes=NULL,
                       normalize="TIC",
                       minModuleSize=2,
                       linkage="average",
                       mzdec=4,
                       cleanup=TRUE,
                       maxt_enforce = FALSE,
                       method = c("fastclust", "liclust"),
                       estimate.mem = FALSE
) {
  timeEnv <- new.env()
  ramclustR.data <- .ramclustR.preprocess(xcmsObj,
                                         ms, 
                                         idmsms, 
                                         taglocation, 
                                         MStag, 
                                         idMSMStag, 
                                         featdelim, 
                                         timepos, 
                                         st, 
                                         sr, 
                                         maxt,
                                         hmax,
                                         sampNameCol,
                                         mspout, 
                                         mslev,
                                         ExpDes,
                                         normalize,
                                         timeEnv = timeEnv)
  
  n <- nrow(ramclustR.data$data1)
  
  # Calculate which blocks need to be processed
  blocksEval <- .ramclustR.blockpred(ramclustR.data$data1, 
                   ramclustR.data$data2,
                   ramclustR.data$times,
                   ramclustR.data$sr,
                   ramclustR.data$st, 
                   ramclustR.data$maxt,
                   maxt_enforce, 
                   blocksize,
                   timeEnv = timeEnv)
  
  
  blocks <- .ramclustR.RCsim(ramclustR.data$data1, 
                           ramclustR.data$data2,
                           ramclustR.data$times,
                           ramclustR.data$sr,
                           ramclustR.data$st, 
                           ramclustR.data$maxt,
                           maxt_enforce, 
                           blocksize,
                           timeEnv = timeEnv,
                           blocksEval = blocksEval)
  #return(ffmat)
  # estimate memory of fastclust vs liclust
  # if(estimate.mem)
  #   .ramclustR.est.mem(ffmat, blocksize, mult)
  
  if(method[[1]] == "fastclust")
    stop("fastclust not currently supported for the new RCsim calculation")
    # RC <- .ramclustR.fastclust(ffmat, blocksize, mult, linkage, ramclustR.data$featnames,
    #                           timeEnv = timeEnv)
  else if(method[[1]] == "liclust")
  {
   require(fastliclust)

  blocksize<-mult*round(blocksize^2/n)
    flInput <- .ramclustR.blockconvert(blocks)

  rm(blocks)
  gc()
  #browser()
  timeEnv$c<-Sys.time()    
  cat('\n', '\n')
  cat(paste("RAMClust distances converted to linkage graph matrix:", 
            round(difftime(timeEnv$c, timeEnv$b, units="mins"), digits=1), "minutes"))
  
  
  cat("\n", "Real size of liclust linkage matrix: ", object.size(flInput), "\n")
    RC <- .ramclustR.liclust(flInput, blocksize, mult, linkage, ramclustR.data$featnames,
                             timeEnv = timeEnv, n)
                             
  }
  else
    stop("No existing clustering method was provided.")
  
  RC <- .ramclustR.postprocess(RC, hmax, deepSplit, minModuleSize, ramclustR.data$times,
                               ramclustR.data$mzs, ramclustR.data$xcmsOrd, collapse, mspout, mslev,
                                     usePheno, xcmsObj, mzdec,
                               ramclustR.data$data1,
                               ramclustR.data$data2,
                               ramclustR.data$ExpDes,
                               timeEnv = timeEnv,
                               msfiles = ramclustR.data$msfiles)
                                         
  return(RC)
  
}

.ramclustR.preprocess <- function(
  xcmsObj=NULL,
  ms=NULL, 
  idmsms=NULL,
  taglocation="filepaths",
  MStag=NULL,
  idMSMStag=NULL, 
  featdelim="_", 
  timepos=2, 
  st=NULL, 
  sr=NULL, 
  maxt=NULL, 
#  deepSplit=FALSE, 
#  blocksize=2000,
#  mult=5,
  hmax=NULL,
  sampNameCol=NULL,
#  collapse=TRUE,
#  usePheno=TRUE,
  mspout=TRUE, 
  mslev=1,
  ExpDes=NULL,
  normalize="TIC",
# minModuleSize=2,
#  linkage="average",
# mzdec=4,
#  cleanup=TRUE,
#  maxt_enforce = FALSE
 timeEnv = environment()
)
{
  
  msfiles <- c()
  msmsfiles <- c()
  
  require(xcms, quietly=TRUE)
  require(ff, quietly=TRUE)
  require(fastcluster, quietly=TRUE)
  require(dynamicTreeCut, quietly=TRUE)
  
  if(is.null(xcmsObj) & is.null(ms))  {
    stop("you must select either 
          1: an MS dataset with features as columns 
             (__)one column may contain sample names, defined by sampNameCol) 
          2: an xcmsObj. If you choose an xcms object, set taglocation: 'filepaths' by default
            and both MStag and idMSMStag")}
  
  if(!is.null(xcmsObj) & mslev==2 & any(is.null(MStag), is.null(idMSMStag), is.null(taglocation)))
  {stop("you must specify the the MStag, idMSMStag, and the taglocations")}
  
  if(is.null(ExpDes) & mspout==TRUE){
    cat("please enter experiment description (see popup window), or set 'mspout=FALSE'")
    ExpDes<-defineExperiment()
  }
  
  if(is.null(ExpDes) & mspout==FALSE){
    warning("using undefined instrumental settings")
    ExpDes<-paramsets$undefined
  }
  
  
  if( normalize!="none"  & normalize!="TIC" & normalize!="quantile") {
    stop("please selected either 'none', 'TIC', or 'quantile' for the normalize setting")}
  
  timeEnv$a<-Sys.time()   
  
  if(is.null(hmax)) {hmax<-0.3}
  ##in using non-xcms data as input
  ##remove MSdata sets and save data matrix alone
  if(!is.null(ms)){
    if(is.null(st)) stop("please specify st: 
      a recommended starting point is half the value of 
      your average chromatographic peak width at half max (seconds)")
    if(is.null(sr)) sr<-0.5
    if(is.null(maxt)) maxt<-60
    if(!is.matrix(ms) & !is.data.frame(ms))
      MSdata<-read.csv(ms, header=TRUE, check.names=FALSE)
    else
      MSdata <- as.data.frame(ms)
    if(!is.null(idmsms)){
      if(!is.matrix(idmsms) & !is.data.frame(idmsms))
        MSMSdata<-read.csv(idmsms, header=TRUE, check.names=FALSE)}
      else
        MSMSdata <- as.data.frame(idmsms)
    if(is.null(idmsms)) { MSMSdata<-MSdata}
    if(is.null(sampNameCol)) {featcol<-1:ncol(MSdata)} else {
      featcol<-setdiff(1:(ncol(MSdata)), sampNameCol)}
    if(is.null(sampNameCol)) {featcol<-1:ncol(MSdata)} else {
      featcol<-setdiff(1:(ncol(MSdata)), sampNameCol)}
    sampnames<-MSdata[,sampNameCol]
    data1<-as.matrix(MSdata[,featcol])
    dimnames(data1)[[1]]<-MSdata[,sampNameCol]
    dimnames(data1)[[2]]<-names(MSdata[,featcol])
    data2<-as.matrix(MSMSdata[,featcol])
    dimnames(data2)[[1]]<-MSMSdata[,sampNameCol]
    dimnames(data2)[[2]]<-names(MSMSdata[,featcol])
    if(!all(dimnames(data1)[[2]]==dimnames(data2)[[2]])) 
    {stop("the feature names of your MS and idMSMS data are not identical")}
    
    if(!all(dimnames(data1)[[1]]==dimnames(data2)[[1]])) 
    {stop("the order and names of your MS and idMSMS data sample names are not identical")}
    
    rtmz<-matrix(
      unlist(
        strsplit(dimnames(data1)[[2]], featdelim)
      ), 
      byrow=TRUE, ncol=2)
    times<-as.numeric(rtmz[,timepos])
    mzs<-as.numeric(rtmz[,which(c(1:2)!=timepos)])
    rm(rtmz)     
  }
  
  ##if xcms object is selected instead of an R dataframe/matrix
  if(!is.null(xcmsObj)){
    if(!class(xcmsObj)=="xcmsSet")
    {stop("xcmsObj must reference an object generated by XCMS, of class 'xcmsSet'")}
    
    if(is.null(st)) st<-round(median(xcmsObj@peaks[,"rtmax"]-xcmsObj@peaks[,"rtmin"])/2, digits=2)
    if(is.null(sr)) sr<-0.5
    if(is.null(maxt)) maxt<-st*20
    
    sampnames<-row.names(xcmsObj@phenoData)
    data12<-groupval(xcmsObj, value="into")
    
    if(taglocation=="filepaths" & !is.null(MStag)) 
    { msfiles<-grep(MStag, xcmsObj@filepaths, ignore.case=TRUE)
      msmsfiles<-grep(idMSMStag, xcmsObj@filepaths, ignore.case=TRUE)
      if(length(intersect(msfiles, msmsfiles)>0)) 
      {stop("your MS and idMSMStag values do not generate unique file lists")}
      if(length(msfiles)!=length(msmsfiles)) 
      {stop("the number of MS files must equal the number of MSMS files")}
      data1<-t(data12[,msfiles])
      row.names(data1)<-sampnames[msfiles]
      data2<-t(data12[,msmsfiles])
      row.names(data2)<-sampnames[msmsfiles]  ##this may need to be changed to dimnames..
      times<-round(xcmsObj@groups[,"rtmed"], digits=3)
      if(any(is.na(times))) {
        do<-which(is.na(times))
        for(x in 1:length(do)) {
          times[do[x]]<-  as.numeric((xcmsObj@groups[do[x],"rtmin"]+ xcmsObj@groups[do[x],"rtmax"])/2)
        }
      }
      # if(any(is.na(times))) {stop("na values still present")} else {print("NAs removed")}
      mzs<-round(xcmsObj@groups[,"mzmed"], digits=4)
    } else {
      data1<-t(data12)
      msfiles<-1:nrow(data1)
      data2<-t(data12)
      times<-round(xcmsObj@groups[,"rtmed"], digits=3)
      mzs<-round(xcmsObj@groups[,"mzmed"], digits=4) 
      if(any(is.na(times))) {
        do<-which(is.na(times))
        for(x in 1:length(do)) {
          times[do[x]]<-  as.numeric((xcmsObj@groups[do[x],"rtmin"]+ xcmsObj@groups[do[x],"rtmax"])/2)
        }
      }
      #if(any(is.na(times))) {stop("na values still present")} else {print("NAs removed")}
    }
  }
  
  
  ##replace na, inf, 0, and NaN with jittered min dataset value
  rpl1<-unique(c(which(is.na(data1)), which(is.nan(data1)), which(is.infinite(data1)), which(data1==0)))
  rpl2<-unique(c(which(is.na(data2)), which(is.nan(data2)), which(is.infinite(data2)), which(data2==0)))
  if(length(rpl1)>0) {data1[rpl1]<-abs(jitter(rep(min(data1, na.rm=TRUE), length(rpl1) ), amount=min(data1/100, na.rm=TRUE)))}
  if(length(rpl2)>0) {data2[rpl2]<-abs(jitter(rep(min(data2, na.rm=TRUE), length(rpl2) ), amount=min(data2/100, na.rm=TRUE)))}
  #if(length(rpl1)>0) {data1[rpl1]<-abs(jitter(rep(min(data1, na.rm=TRUE), length(rpl1) ), amount=min(data1/100, na.rm=TRUE)))}
  #if(length(rpl2)>0) {data2[rpl2]<-abs(jitter(rep(min(data2, na.rm=TRUE), length(rpl2) ), amount=min(data2/100, na.rm=TRUE)))}
  data1[which(data1<0)]<-abs(data1[which(data1<0)])
  data2[which(data2<0)]<-abs(data2[which(data2<0)])
  
  ##Optional normalization of data, either Total ion signal or quantile
  
  if(normalize=="TIC") {
    data1<-(data1/rowSums(data1))*mean(rowSums(data1), na.rm=TRUE)
    data2<-(data2/rowSums(data2))*mean(rowSums(data2), na.rm=TRUE)
  }
  if(normalize=="quantile") {
    library(preprocessCore)
    data1<-t(preprocessCore::normalize.quantiles(t(data1)))
    data2<-t(preprocessCore::normalize.quantiles(t(data2)))	
  }
  
  
  ##retention times and mzs vectors
  
  ##sort rt vector and data by retention time
  xcmsOrd<-order(times)
  data1<-data1[,order(times)]
  data2<-data2[,order(times)]
  mzs<-mzs[order(times)]
  times<-times[order(times)]
  
  ##extract names (would like to be pulling from XCMS set instead...)
  featnames<-paste(mzs, "_", times, sep="")
  dimnames(data1)[[2]]<-featnames
  dimnames(data2)[[2]]<-featnames
  
  return(list(
    data1=data1, data2=data2, mzs=mzs, times=times, xcmsOrd=xcmsOrd, featnames=featnames,
    sr=sr, st=st, maxt=maxt, hmax=hmax, ExpDes=ExpDes, msfiles=msfiles
    #, msmsfiles=msmsfiles
  ))
  
}
  

.ramclustR.RCsim <- function(data1, data2, times, sr=NULL, st=NULL, maxt=NULL, maxt_enforce=FALSE, blocksize=2000,
                            timeEnv = environment(), blocksEval)
{
  ##establish some constants for downstream processing
  n<-ncol(data1)
  vlength<-(n*(n-1))/2
  nblocks<-floor(n/blocksize)
  
  
  ##make list of all row and column blocks to evaluate
  eval1<-expand.grid(0:nblocks, 0:nblocks)
  names(eval1)<-c("j", "k") #j for cols, k for rows
  eval1<-eval1[which(eval1[,"j"]<=eval1[,"k"]),] #upper triangle only
  bl<-nrow(eval1)
  cat('\n', paste("calculating ramclustR similarity: nblocks = ", sum(blocksEval)))
  cat('\n', "finished:")
  
  RCsim<-function(bl, env)  {
    gc()
    cat(bl,' ')
    j<-eval1[bl,"j"]  #columns
    k<-eval1[bl,"k"]  #rows
    
    # Determine row and column range to process:
    # startc-stopc are columns
    # startr-stopr are rows
    
    startc<-min((1+(j*blocksize)), n)
    if ((j+1)*blocksize > n) {
      stopc<-n} else {
        stopc<-(j+1)*blocksize}
    startr<-min((1+(k*blocksize)), n)
    if ((k+1)*blocksize > n) {
      stopr<-n} else {
        stopr<-(k+1)*blocksize}
    
    # mint doesn't need to be calculated anymore, since we do this in blockpred now
    
        dt <- abs(outer(times[startr:stopr], times[startc:stopc], FUN="-"))
        temp1<-round(exp(-(( (dt))^2)/(2*(st^2))), 
                     
                     digits=20 )
        #stopifnot(max(temp)!=0)
        #ffrt[startr:stopr, startc:stopc]<- temp
        temp2<-round (exp(-((1-(pmax(  cor(data1[,startr:stopr], data1[,startc:stopc]),
                                       cor(data1[,startr:stopr], data2[,startc:stopc]),
                                       cor(data2[,startr:stopr], data2[,startc:stopc])  )))^2)/(2*(sr^2))), 
                      
                      digits=20 )		
        #ffcor[startr:stopr, startc:stopc]<-temp
        temp<- 1-(temp1*temp2)
        temp[which(is.nan(temp))]<-1
        temp[which(is.na(temp))]<-1
        temp[which(is.infinite(temp))]<-1
        # set distant entries to 0!
        if(maxt_enforce)
          temp[dt > maxt] <- 1
        
        # annotate the rows-columns:
        rownames(temp) <- as.character(startr:stopr)
        colnames(temp) <- as.character(startc:stopc)
        #browser()
        return(temp)
        
    
    }
    
  # ffmat[995:1002,995:1002]
  
  ##Call the similarity scoring function
  system.time(blocks <- sapply(seq_len(bl)[blocksEval], function(bl) RCsim(bl, env)))
  #RCsim(bl=1:bl)
  
  timeEnv$b<-Sys.time()
  
  cat('\n','\n' )
  cat(paste("RAMClust feature similarity matrix calculated and stored:", 
            round(difftime(timeEnv$b, timeEnv$a, units="mins"), digits=1), "minutes"))
  
  #cleanup
  #delete.ff(ffrt)
  #rm(ffrt)
  #delete.ff(ffcor)
  #rm(ffcor)
  gc()
  return(blocks)
}


.ramclustR.fastclust <- function(ffmat, blocksize, mult, linkage, featnames,
                                timeEnv = environment())
{
  n <- nrow(ffmat)
  vlength<-(n*(n-1))/2
  
  ##extract lower diagonal of ffmat as vector
  blocksize<-mult*round(blocksize^2/n)
  nblocks<-floor(n/blocksize)
  remaind<-n-(nblocks*blocksize)
  
  ##create vector for storing dissimilarities
  RC<-vector(mode="integer", length=vlength)
  
  for(k in 0:(nblocks)){
    startc<-1+(k*blocksize)
    if ((k+1)*blocksize > n) {
      stopc<-n} else {
        stopc<-(k+1)*blocksize}
    temp<-ffmat[startc:nrow(ffmat),startc:stopc]
    temp<-temp[which(row(temp)-col(temp)>0)]
    if(exists("startv")==FALSE) startv<-1
    stopv<-startv+length(temp)-1
    RC[startv:stopv]<-temp
    gc()
    startv<-stopv+1
    rm(temp)
    gc()
  }    
  rm(startv)
  gc()
  
  cat("\n", "Real size of fastclust dist vector: ", object.size(RC), "\n")
  ##convert vector to distance formatted object
  RC<-structure(RC, Size=(n), Diag=FALSE, Upper=FALSE, method="RAMClustR", Labels=featnames, class="dist")
  gc()
  
  timeEnv$c<-Sys.time()    
  cat('\n', '\n')
  cat(paste("RAMClust distances converted to distance object:", 
            round(difftime(timeEnv$c, timeEnv$b, units="mins"), digits=1), "minutes"))
  
  ##cleanup
  delete.ff(ffmat)
  rm(ffmat)
  gc()
  
  
  ##cluster using fastcluster package,
  system.time(RC<-hclust(RC, method=linkage))
  
  gc()
  timeEnv$d<-Sys.time()    
  cat('\n', '\n')    
  cat(paste("fastcluster based clustering complete:", 
            round(difftime(timeEnv$d, timeEnv$c, units="mins"), digits=1), "minutes"))
  #browser()
  return(RC) 
}


.ramclustR.liclust <- function(flInput, blocksize, mult, linkage, featnames,
                               timeEnv = environment(), n)
{
 
  # fastLiclust performs operation in place.
  n <- fastLiclust(flInput$linkmat, flInput$sim, flInput$weights)
  timeEnv$cc <- Sys.time()
  cat('\n', '\n')
  cat(paste("liclust based clustering complete:", 
            round(difftime(timeEnv$cc, timeEnv$b, units="mins"), digits=1), "minutes"))
  #browser()
  flInput <- crop(flInput)
  RC <- toHclust(flInput$linkmat, flInput$sim)
  RC$labels <- featnames
  RC$method <- linkage
  RC$dist.method <- "RAMclustR"
  RC$call <-  "fastLiclust(flInput$linkmat, flInput$sim, flInput$weights)"

  gc()
  timeEnv$d<-Sys.time()    
  cat('\n', '\n')    
  cat(paste("Conversion to hclust format complete:", 
            round(difftime(timeEnv$d, timeEnv$cc, units="mins"), digits=1), "minutes"))
  RC
  
  
}
  
.ramclustR.postprocess <- function(RC, hmax, deepSplit, minModuleSize, times, mzs, xcmsOrd, collapse, mspout, mslev,
                                   usePheno, xcmsObj, mzdec, data1, data2, ExpDes,
                                   timeEnv = environment(), msfiles)
{
  n <- ncol(data1)
  
  if(minModuleSize==1) {
    clus<-cutreeDynamicTree(RC, maxTreeHeight=hmax, deepSplit=deepSplit, minModuleSize=2)
    sing<-which(clus==0)
    clus[sing]<-max(clus)+1:length(sing)
  }
  if(minModuleSize>1) {
    clus<-cutreeDynamicTree(RC, maxTreeHeight=hmax, deepSplit=deepSplit, minModuleSize=minModuleSize)
  }
  gc()
  
  
  RC$featclus<-clus
  RC$frt<-times
  RC$fmz<-mzs
  RC$xcmsOrd<-xcmsOrd
  msint<-rep(0, length(RC$fmz))
  for(i in 1:ncol(data1)){
    msint[i]<-weighted.mean(data1[,i], data1[,i])
  }
  RC$msint<-msint
  
  if(mslev==2) {
    msmsint<-rep(0, length(RC$fmz))	
    for(i in 1:ncol(data1)){	
      msmsint[i]<-weighted.mean(data2[,i], data2[,i])
    }
    RC$msmsint<-msmsint
  }
  
  ##new cleanup section to collapse reduntant clusters groups into a single cluster
  ##currently only reporting redundancy, need to next modify the original cluster 'clrt' with the new cluster data
  
  #   if(cleanup) {
  #     cat('\n', "... checking for potential split feature groups")
  #     wts<-colSums(data1[])
  #     tmp<-matrix(nrow=nrow(data1), ncol=max(clus))
  #     was<-1:max(clus)
  #     for (ro in 1:nrow(tmp)) { 
  #       for (co in 1:ncol(tmp)) {
  #         tmp[ro,co]<- weighted.mean(data1[ro,which(tmp==co)], wts[which(tmp==co)])
  #       }
  #     }
  #     clrt<-aggregate(RC$frt, by=list(RC$featclus), FUN="mean")
  #     for(x in 1:max(clus)){
  #       check<-x-1+which(clrt[x:length(clrt)]>=(clrt[x]-(0.5*st))  &  clrt[x:length(clrt)]<=(clrt[x]+(0.5*st)))
  #       check<-check[-1]
  #       if(length(check)>1) {
  #         rs<-cor(tmp[,x], tmp[,check])
  #         if(length(which(rs>0.7))>0) {
  #           paste("cl", x, "is likely redundant with cl", check[which(rs>0.7)])
  #         }
  #       }
  #     }
  #     cat('\n', '\n')
  #     cat(paste("done checking...", '\n'))
  #   }
  #   
  clrt<-aggregate(RC$frt, by=list(RC$featclus), FUN="mean")
  RC$clrt<-clrt[which(clrt[,1]!=0),2]
  clrtsd<-aggregate(RC$frt, by=list(RC$featclus), FUN="sd")
  RC$clrtsd<-clrtsd[which(clrtsd[,1]!=0),2]
  
  RC$nfeat<-as.vector(table(RC$featclus)[2:max(RC$featclus)])
  RC$nsing<-length(which(RC$featclus==0))
  
  timeEnv$e<-Sys.time() 
  cat('\n', '\n')
  cat(paste("dynamicTreeCut based pruning complete:", 
            round(difftime(timeEnv$e, timeEnv$d, units="mins"), digits=1), "minutes"))
  
  timeEnv$f<-Sys.time()
  cat('\n', '\n')
  cat(paste("RAMClust has condensed", n, "features into",  max(clus), "spectra in", round(difftime(
    timeEnv$f, timeEnv$a, 
    units="mins"), digits=1), "minutes", '\n'))
  
  RC$ExpDes<-ExpDes
  RC$cmpd<-paste("C", 1:length(RC$clrt), sep="")
  RC$ann<-RC$cmpd
  RC$annconf<-rep("", length(RC$clrt))
  RC$annnotes<-rep("", length(RC$clrt))
  RC$MSdata<-data1
  if(mslev==2) RC$MSMSdata<-data2  
  
  if(collapse=="TRUE") {
    cat('\n', '\n', "... collapsing features into spectra")
    wts<-colSums(data1[])
    RC$SpecAbund<-matrix(nrow=nrow(data1), ncol=max(clus))
    for (ro in 1:nrow(RC$SpecAbund)) { 
      for (co in 1:ncol(RC$SpecAbund)) {
        RC$SpecAbund[ro,co]<- weighted.mean(data1[ro,which(RC$featclus==co)], wts[which(RC$featclus==co)])
      }
    }
    dimnames(RC$SpecAbund)[[2]]<-paste("C", 1:ncol(RC$SpecAbund), sep="")
    if(!usePheno | is.null(xcmsObj)) {dimnames(RC$SpecAbund)[[1]]<-dimnames(RC$MSdata)[[1]]} 
    if(usePheno & !is.null(xcmsObj)) {dimnames(RC$SpecAbund)[[1]]<-as.vector(xcmsObj@phenoData[,1])[msfiles]}
    #if(!usePheno) {dimnames(RC$SpecAbund)[[1]]<-dimnames(RC$MSdata)[[1]]} 
    #if(usePheno) {dimnames(RC$SpecAbund)[[1]]<-xcmsObj@phenoData[,1][msfiles]}
    timeEnv$g<-Sys.time()
    cat('\n', '\n')
    cat(paste("RAMClustR has collapsed feature quantities
             into spectral quantities:", round(difftime(timeEnv$g, timeEnv$f, units="mins"), digits=1), "minutes", '\n'))
  }
  
  rm(data1)
  rm(data2)
  if(!is.null(RC$SpecAbund)) {
    if(length(dimnames(RC$SpecAbund)[[1]])> length(unique(dimnames(RC$SpecAbund)[[1]]))) {
      RC$SpecAbundAve<-aggregate(RC$SpecAbund[,1:ncol(RC$SpecAbund)], 
                                 by=list(dimnames(RC$SpecAbund)[[1]]), 
                                 FUN="mean", simplify=TRUE)
      dimnames(RC$SpecAbundAve)[[1]]<-RC$SpecAbundAve[,1]
      RC$SpecAbundAve<-as.matrix(RC$SpecAbundAve[,2:ncol(RC$SpecAbundAve)])
      dimnames(RC$SpecAbundAve)[[2]]<-dimnames(RC$SpecAbund)[[2]]
      gc()
    }
  }
  gc()
  
  if(mspout==TRUE){ 
    cat(paste("writing msp formatted spectra...", '\n'))
    dir.create("spectra")
    libName<-paste("spectra/", ExpDes[[1]]["Experiment", 1], ".mspLib", sep="")
    file.create(file=libName)
    for (m in 1:as.numeric(mslev)){
      for (j in 1:max(RC$featclus)) {
        #print(paste(j,"_", sep=""))
        sl<-which(RC$featclus==j)
        wm<-vector(length=length(sl))
        if(m==1) {wts<-rowSums(RC$MSdata[,sl])
                  for (k in 1:length(sl)) {     
                    wm[k]<-weighted.mean(RC$MSdata[,sl[k]], wts)
                  }}
        if(m==2) {wts<-rowSums(RC$MSMSdata[,sl])
                  for (k in 1:length(sl)) {    
                    wm[k]<-weighted.mean(RC$MSMSdata[,sl[k]], wts)
                  }}
        mz<-round(RC$fmz[sl][order(wm, decreasing=TRUE)], digits=mzdec)
        rt<-RC$frt[sl][order(wm, decreasing=TRUE)]
        wm<-round(wm[order(wm, decreasing=TRUE)])
        mrt<-mean(rt)
        npeaks<-length(mz)
        for (l in 1:length(mz)) {
          ion<- paste(mz[l], wm[l])
          if(l==1) {specdat<-ion} 
          if(l>1)  {specdat<-c(specdat, " ", ion)}
        }
        cat(
          paste("Name: C", j, sep=""), '\n',
          paste("SYNON: $:00in-source", sep=""), '\n',
          paste("SYNON: $:04", sep=""), '\n', 
          paste("SYNON: $:05", if(m==1) {ExpDes[[2]]["CE1", 1]} else {ExpDes$instrument["CE2", "InstVals"]}, 
                
                sep=""), '\n',
          paste("SYNON: $:06", ExpDes[[2]]["mstype", 1], sep=""), '\n',           #mstype
          paste("SYNON: $:07", ExpDes[[2]]["msinst", 1], sep=""), '\n',           #msinst
          paste("SYNON: $:09", ExpDes[[2]]["chrominst", 1], sep=""), '\n',        #chrominst
          paste("SYNON: $:10", ExpDes[[2]]["ionization", 1], sep=""),  '\n',      #ionization method
          paste("SYNON: $:11", ExpDes[[2]]["msmode", 1], sep=""), '\n',           #msmode
          paste("SYNON: $:12", ExpDes[[2]]["colgas", 1], sep=""), '\n',           #collision gas
          paste("SYNON: $:14", ExpDes[[2]]["msscanrange", 1], sep=""), '\n',      #ms scanrange
          paste("SYNON: $:16", ExpDes[[2]]["conevolt", 1], sep=""), '\n',         #conevoltage
          paste("Comment: Rt=", round(mrt, digits=2), 
                "  Contributor=", ExpDes[[1]]["Contributor", 1], 
                "  Study=", ExpDes[[1]]["Experiment", 1], 
                sep=""), '\n',
          paste("Num Peaks:", npeaks), '\n',
          paste(specdat), '\n', '\n', sep="", file=libName, append= TRUE)
      }
    }
    cat(paste('\n', "msp file complete", '\n')) 
  }  
  return(RC)
}

.ramclustR.est.mem <- function(ffmat, blocksize, mult)
{
  require(fastliclust)
  n <- nrow(ffmat)
  blocksize<-mult*round(blocksize^2/n)
  cat("\n\n")
  cat("Estimating sizes", "\n")
  # lower triangle of distance matrix:
  # n^2/2 * size(numeric) + 200
  dist <- ((n*n)/2 - n)*8 + 200
  # number of links
  nlinks <- sum_ff(ffmat, ffmat < 1, by=blocksize)
  
  # linkage matrix: nlinks * size(integer) * 2 + 200
  # weight matrix: nlinks * size(integer) + 40
  # similarity matrix: nlinks * size(numeric) + 40
  # total: nlinks * (3 size(int) + size(num) ) + 280
  # = nlinks * (12+8) + 280
  # = nlinks * 20 + 280
  links  <- nlinks * 20 + 280
  cat("Estimated size for fastclust: ", dist, "\n")
  cat("Estimated size for liclust: ", links, "\n")
  
}
